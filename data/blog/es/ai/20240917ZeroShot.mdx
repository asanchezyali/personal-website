---
title: 'Clasificaci칩n Zero-Shot de texto'
date: '2024/09/17'
tags: ['IA', 'Zero-Shot Learning', 'Transformers', 'Hugging Face']
draft: false
time: '15 min'
summary: 'La clasificaci칩n Zero-Shot de texto (ZSTC) es una t칠cnica de aprendizaje automatizado que permite a los modelos clasificar textos en categor칤as sin haber sido entrenados previamente en esas categor칤as espec칤ficas. Utiliza modelos de lenguaje pre-entrenados, como BART o GPT, que han aprendido a comprender las relaciones sem치nticas entre palabras y frases durante su pre-entrenamiento. Este enfoque permite al modelo generalizar su conocimiento y hacer inferencias sobre nuevas categor칤as bas치ndose en un texto dado, sin necesidad de ejemplos etiquetados.'
bibliography: references-data.bib
canonicalUrl: 'https://www.asanchezyali.com/blog/es/number-theory/20230108DivisionAlgorithm'
headerImage: '/images/ai/zero-shot.jpg'
images: ['/images/ai/zero-shot.jpg']
language: 'es'
---

游닇 Nota al lector: Este contenido es una colaboraci칩n entre inteligencia artificial y un ser humano. Todo el material ha sido cuidadosamente revisado y ajustado para garantizar su precisi칩n y utilidad. El contenido se ha creado combinando y procesando informaci칩n de diversas fuentes confiables de internet, citadas a lo largo del texto y en las referencias finales. Nuestro objetivo es ofrecerte informaci칩n valiosa y bien documentada.

Imagina un estudiante que puede aprobar un examen sobre un tema que nunca ha estudiado. 쮺칩mo es esto posible? La
respuesta radica en la capacidad de comprensi칩n y generalizaci칩n de los seres humanos. Los humanos pueden aplicar el
conocimiento adquirido en un contexto a situaciones nuevas y desconocidas. Este proceso de generalizaci칩n y adaptaci칩n
es fundamental para el aprendizaje y la inteligencia. Ahora, piensa en una inteligencia artificial capaz de clasificar
conceptos que jam치s ha visto en su entrenamiento. 쮼s posible que una IA pueda realizar esta tarea? La respuesta es s칤,
y se conoce como [_Zero-Shot Learning_](https://en.wikipedia.org/wiki/Zero-shot_learning) (ZSL). En este art칤culo, exploraremos c칩mo los modelos de lenguaje pueden realizar clasificaciones de texto sin
necesidad de entrenamiento previo en un dominio espec칤fico.

## Clasificaci칩n _Zero-Shot_ de texto

La clasificaci칩n _Zero-Shot_ de texto (ZSTC por sus siglas en ingl칠s, [_Zero-Shot Text Classification_](https://huggingface.co/tasks/zero-shot-classification)) es una t칠cnica de
aprendizaje automatizado que permite a los modelos clasificar textos en categor칤as sin haber sido entrenados previamente
en esas categor칤as espec칤ficas. Utiliza modelos de lenguaje pre-entrenados, como
[BART](https://huggingface.co/facebook/bart-large-mnli) o [Distil Roberta](https://huggingface.co/cross-encoder/nli-distilroberta-base), que han aprendido a
comprender las relaciones sem치nticas entre palabras y frases durante su pre-entrenamiento. Este enfoque permite al
modelo generalizar su conocimiento y hacer inferencias sobre nuevas categor칤as bas치ndose en un texto dado, sin necesidad
de ejemplos etiquetados ([Wenpeng Yin et al, 2019](https://arxiv.org/pdf/1909.00161),
[Paul Puri et al, 2019](https://arxiv.org/abs/1912.10165), [Tassallah Abdullahi et al, 2024](https://arxiv.org/abs/1912.10165)). Esta capacidad representa un avance significativo respecto al aprendizaje supervisado
tradicional, donde los modelos necesitan ejemplos de cada clase para realizar una clasificaci칩n precisa.

El t칠rmino 춺_Zero-Shot_췉 se refiere a la habilidad de un modelo de manejar tareas o hacer predicciones sin
entrenamiento espec칤fico previo. En este enfoque, el modelo debe aprovechar y transferir el conocimiento adquirido
durante sus entrenamiento en otras tareas o categor칤as relacionadas para abordar estas nuevas categor칤as no vistas
previamente.

La clasificaci칩n _Zero-Shot_ es particularmente 칰til en escenarios donde:

1. Es poco pr치ctico o costoso etiquetar ejemplos de entrenamiento para todas las categor칤as.
2. Las categor칤as cambian con el tiempo y es dif칤cil mantener un conjunto de entrenamiento actualizado.
3. Se requiere una r치pida adaptaci칩n a nuevas categor칤as sin necesidad de reentrenar el modelo.

Veamos un ejemplo pr치ctico de c칩mo se puede implementar ZSTC utilizando modelos de
lenguaje pre-entrenados:

```python showLineNumbers
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)
text = "The new restaurant in the city center offers a unique culinary experience, blending traditional flavors with modern techniques."
candidate_labels = ["Restaurant review", "Local news", "Cooking recipe", "Tourist guide"]
result = classifier(text, candidate_labels, multi_label=True)

print(f"Text: {text}")
print(f"Most likely label: {result['labels'][0]}")
print(f"Score: {result['scores'][0]:.4f}")

```

```
## Salida
The new restaurant in the city center offers a unique culinary experience, blending traditional flavors with modern techniques.
Most likely label: Local news
Score: 0.5561
```

En este ejemplo, estamos utilizando un modelo pre-entrenado para clasificar un texto en categor칤as que posiblemente no
haya visto antes. El modelo [BART-large-mnli](https://huggingface.co/facebook/bart-large-mnli) de Facebook es un modelo de lenguaje pre-entrenado que ha sido ajustado en
la tarea de ZSTC. Al proporcionar el texto y una lista de etiquetas candidatas, el modelo devuelve la
etiqueta m치s probable y la puntuaci칩n asociada a esa predicci칩n. En este caso, el modelo clasifica el texto como
춺Local news췉 con una puntuaci칩n de 0.5561.

Existen muchos enfoques para resolver los problemas de clasificaci칩n _Zero-Shot_: [Latent
Embeddings](https://arxiv.org/abs/1603.08895), [Text Aware Representation of
Sentence](https://aclanthology.org/2020.coling-main.285/) and [Natural Language
Inference](https://arxiv.org/abs/1909.00161). En este art칤culo, nos centraremos en ZSTC basando en inferencias de
lenguaje natural (NLI, por sus siglas en ingl칠s [_Natural Language
Inference_](https://en.wikipedia.org/wiki/Textual_entailment)). Este enfoque utiliza modelos de lenguaje pre-entrenados
para inferir sobre la relaci칩n entre una premisa (el texto de entrada) y una hip칩tesis (la descripci칩n de una categor칤a
candidata) para realizar la clasificaci칩n, como veremos a continuaci칩n.

## 쮺칩mo funciona la clasificaci칩n _Zero-Shot_ basada en NLI?

La Inferencia de Lenguaje Natural (NLI, por sus siglas en ingl칠s) es la tarea de determinar si una afirmaci칩n
(hip칩tesis) es verdadera, falsa o neutral dada una premisa. Este concepto se puede adaptar ingeniosamente a tareas de
clasificaci칩n _Zero-Shot_, lo que nos permite clasificar textos en categor칤as sin necesidad de entrenamiento previo en
esas categor칤as espec칤ficas.

<ImageBox
  src="/images/ai/zero-shot-v04.png"
  alt="Arquitectura de clasificaci칩n Zero-Shot basada en NLI"
  width="819px"
  height="910px"
>
  **Figura 1**. Arquitectura de clasificaci칩n Zero-Shot basada en NLI.
</ImageBox>

En este enfoque, tratamos la premisa como el texto de entrada que queremos clasificar, y la hip칩tesis como la
descripci칩n de una categor칤a candidata. Por ejemplo, si queremos clasificar un texto en la categor칤a 춺Tecnolog칤a췉,
podemos formular la tarea de la siguiente manera:

- Premisa: 춺El nuevo smartphone tiene un procesador potente y una c치mara de alta resoluci칩n.췉
- Hip칩tesis: 춺Este texto es sobre tecnolog칤a.췉

El modelo NLI evaluar치 la relaci칩n entre la premisa y la hip칩tesis para determinar si el texto pertenece a la categor칤a
de tecnolog칤a. Este proceso se repite para cada categor칤a candidata que queramos considerar.

<ImageBox
  src="/images/ai/zero-shot-v05.png"
  alt="Proceso de tokenizaci칩n en clasificaci칩n Zero-Shot."
  width="830px"
  height="350px"
>
  **Figura 2**. Proceso de tokenizaci칩n en clasificaci칩n Zero-Shot.
</ImageBox>

El proceso comienza con la tokenizaci칩n, donde el texto de entrada (premisa) y la descripci칩n de la categor칤a
(hip칩tesis) se convierten en una secuencia de tokens que el modelo puede procesar. Como se muestra en la Figura 2, esta
secuencia de tokens se representa como un par de oraciones que luego se convierte en una seria de IDs de entrada que el
modelo utilizar치.

Una vez tenemos los IDs de entrada, el modelo NLI los procesa para generar _logits_ (puntuaciones). Estos logits
representa las puntuaciones brutas para cada clase posible (contradicci칩n, neutralidad, o implicaci칩n) en la tarea del
NLI.

<ImageBox
  src="/images/ai/zero-shot-v06.png"
  alt="Logits generados por el modelo NLI."
  width="410px"
  height="255px"
>
  **Figura 3**. Logits generados por el modelo NLI.
</ImageBox>

Como se muestra en la Figura 3, el modelo produce un conjunto de logits para cada par premisa-hip칩tesis. En este caso,
vemos que el logit m치s alto corresponde a la clase de implicaci칩n (entailment), lo que sugiere que el texto de entrada
est치 fuertemente relacionado con la categor칤a propuesta en la hip칩tesis.

Para casos de clasificaci칩n multi-clase o multi-etiqueta, repetimos este proceso para cada categor칤a candidata.

<ImageBox
  src="/images/ai/zero-shot-v07.png"
  alt="Proceso de clasificaci칩n multi-clase Zero-Shot."
  width="680px"
  height="870px"
>
  **Figura 7**. Proceso de clasificaci칩n multi-clase Zero-Shot.
</ImageBox>

La Figura 4 ilustra c칩mo se maneja la clasificaci칩n multi-clase. El mismo texto de entrada se empareja con m칰ltiples
hip칩tesis, una para cada categor칤a candidata. El modelo genera logits para cada par, y luego aplicamos la funci칩n
softmax a estos logits para obtener probabilidades normalizadas para cada categor칤a.

Matem치ticamente, la probabilidad de que el texto pertenezca a una categor칤a espec칤fica se calcula utilizando la funci칩n softmax:

$$
\begin{equation}
P(\text{categor칤a}_i\; |\; \text{texto}) = \frac{e^{z_i}}{\sum_{j=i}^{N} e^{z_j}}
\end{equation}
$$

Donde $z_i$ es el $\text{logit}$ asociado a la categor칤a $i$ y $N$ es el n칰mero total de categor칤as. La funci칩n
$\text{softmax}$ normaliza los $\text{logits}$ para obtener una distribuci칩n de probabilidad sobre las etiquetas
candidatas.

En Python podemos implementar la clasificaci칩n _Zero-Shot_ utilizando la biblioteca `transformers` de [Hugging Face](https://huggingface.co/docs/transformers/index), que
proporciona una interfaz sencilla para trabajar con modelos de lenguaje pre-entrenados. A continuaci칩n, se muestra un ejemplo de c칩mo implementar la clasificaci칩n _Zero-Shot_ en Python utilizando el modelo BART-large-mnli de Facebook:

```python showLineNumbers
import numpy as np
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# Cargar modelo y tokenizador preentrenados
model = AutoModelForSequenceClassification.from_pretrained("facebook/bart-large-mnli")
tokenizer = AutoTokenizer.from_pretrained("facebook/bart-large-mnli")

def zero_shot_classify(text, labels):
    # Crear hip칩tesis basadas en las etiquetas candidatas
    hypothesis = [f"This text is about {label}." for label in labels]
    premise = [text] * len(labels)

    # Tokenizar entradas (premisa e hip칩tesis) para el modelo
    inputs = tokenizer(premise, hypothesis, return_tensors="pt", padding=True, truncation=True)

    # Generar predicciones con el modelo
    with torch.no_grad():  # Desactivar c치lculo de gradientes para inferencia
        logits = model(**inputs).logits[:, [0, 2]]

    probs = logits.softmax(dim=1)

    # Extraer las probabilidades correspondientes a la etiqueta positiva (칤ndice 1)
    label_probs = probs[:, 1]

    return dict(zip(labels, label_probs.tolist()))

# Texto de entrada y etiquetas candidatas
text = "The new smartphone has a powerful processor and high-resolution camera."
labels = ["technology", "food", "sports"]

# Clasificaci칩n Zero-Shot
results = zero_shot_classify(text, labels)
print(results)
```

```
## Salida
{'technology': 0.9836695194244385, 'food': 0.0005292915157042444, 'sports': 0.0027664615772664547}
```

## Ventajas de ZSTC

ZSTC ofrece varias ventajas sobre los enfoques tradicionales de clasificaci칩n,
especialmente en escenarios donde la disponibilidad de datos etiquetados es limitada o costosa. Veamos algunas de las
ventajas clave de este enfoque.

### Flexibilidad y adaptabilidad

Los modelos _Zero-Shot_, al utilizar modelos de lenguaje pre-entrenados, pueden adaptarse r치pidamente a nuevas categor칤as o tareas sin necesidad de entrenamiento adicional. Esto permite una mayor flexibilidad y adaptabilidad en entornos donde las categor칤as cambian con frecuencia o donde es dif칤cil obtener ejemplos de entrenamiento para todas las categor칤as. Un ejemplo pr치ctico puede verse a continuaci칩n, donde se a침aden nuevas etiquetas sin necesidad de ajustar el modelo:

```python showLineNumbers
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)

# Textos y etiquetas existentes
texts = ["The new AI algorithm outperforms humans in chess",
         "The latest operating system update improves security"]
labels = ["artificial intelligence", "software"]

# Nuevo texto y etiqueta
new_text = "The 3D printer creates custom prosthetics for patients"
new_label = "medical technology"

# Clasificaci칩n Zero-Shot con la nueva etiqueta
all_labels = labels + [new_label]
for text in texts + [new_text]:
    result = classifier(text, all_labels, multi_label=True)
    print(f"Text: {text}")
    print(f"Classification: {result['labels'][0]}")
    print(f"Confidence: {result['scores'][0]:.2f}\n")
```

```
## Salida
Text: The new AI algorithm outperforms humans in chess
Classification: artificial intelligence
Confidence: 0.77

Text: The latest operating system update improves security
Classification: software
Confidence: 0.99

Text: The 3D printer creates custom prosthetics for patients
Classification: medical technology
Confidence: 0.99
```

En este ejemplo, podemos ver c칩mo el modelo es capaz clasificar correctamente un texto en una nueva categor칤a no vista
previamente, 춺medical technology췉, con alta confianza.

### Reducci칩n de la necesidad de datos etiquetados

En muchos escenarios del mundo real, algunas clases pueden tener muy pocos ejemplos de entrenamiento. La clasificaci칩n _Zero-Shot_ brilla en estas situaciones:

- Permite la clasificaci칩n en categor칤as raras o poco representadas
- Es 칰til en dominios especializados donde la recopilaci칩n de datos es costosa o dif칤cil

### Eficiencia en recursos y tiempo

La clasificaci칩n _Zero-Shot_ elimina la necesidad de recopilar y etiquetar grandes cantidades de datos de entrenamiento
para cada categor칤a. Esto ahorra tiempo y recursos al evitar el proceso de recopilaci칩n, limpieza y etiquetado de datos,
y permite una r치pida adaptaci칩n a nuevas categor칤as sin necesidad de reentrenar el modelo.

### Escalabilidad a un gran n칰mero de categor칤as

Los m칠todos tradicionales de clasificaci칩n pueden ser limitados en las cantidad de categor칤as que pueden manejar. La
clasificaci칩n _Zero-Shot_ maneja este problema de manera elegante:

- Puede manejar potencialmente un n칰mero ilimitado de categor칤as.
- No sufre de desequilibrios de clases, ya que no requiere un conjunto de entrenamiento equilibrado.

### Transferencia de conocimiento entre dominios

La clasificaci칩n _Zero-Shot_ permite una forma de transferencia de conocimiento entre dominios:

- Utiliza el conocimiento general del modelo de lenguaje pre-entrenado para inferir sobre nuevos dominios.
- Puede adaptar el conocimiento de un dominio a otro relacionado.

Ejemplo de transferencia de conocimiento entre dominios:

```python showLineNumbers
# Clasificaci칩n en un nuevo dominio
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)
tech_text = "The new smartphone features a high-resolution OLED display"
medical_text = "The patient exhibits symptoms of acute bronchitis"

diverse_labels = ["technology", "medicine", "sports", "cooking"]

for text in [tech_text, medical_text]:
    result = classifier(text, diverse_labels)
    print(f"Texto: {text}")
    print(f"Clasificaci칩n: {result['labels'][0]}")
    print(f"Confianza: {result['scores'][0]:.2f}\n")
```

```
## Salida
Texto: The new smartphone features a high-resolution OLED display
Clasificaci칩n: technology
Confianza: 0.99

Texto: The patient exhibits symptoms of acute bronchitis
Clasificaci칩n: medicine
Confianza: 0.89
```

### Flexibilidad en la formulaci칩n de clases.

La clasificaci칩n _Zero-Shot_ permite una gran flexibilidad en c칩mo se formulan las clases:

- Las clases puede ser descritas con frases o incluso con oraciones completas.
- Permite una clasificaci칩n m치s matizada y contextual.

```python showLineNumbers
# Clasificaci칩n con descripciones de clase detalladas
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)
text = "The company announced record profits this quarter"
detailed_labels = [
    "Financial news about corporate performance",
    "Technology advancements in the business sector",
    "Environmental impact of corporate activities"
]

result = classifier(text, detailed_labels)
print(f"Texto: {text}")
print(f"Clasificaci칩n: {result['labels'][0]}")
print(f"Confianza: {result['scores'][0]:.2f}")
```

```
Texto: The company announced record profits this quarter
Clasificaci칩n: Financial news about corporate performance
Confianza: 0.99
```

## Manejo de etiquetas m칰ltiples

Los modelos de lenguaje permite la ZSTC con etiquetas m칰ltiples, es decir, la posibilidad de
asignar m치s de una etiqueta a un texto. Esto es 칰til en escenarios donde un texto puede pertenecer a varias categor칤as
simult치neamente.

Veamos un ejemplo pr치ctico de c칩mo se puede implementar:

```python showLineNumbers
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)

text = "The new smartphone features a high-resolution camera, 5G connectivity, and a powerful AI chip."
labels = ["camera quality", "network technology", "processing power", "battery life"]

result = classifier(text, labels, multi_label=True)

print("Text:", text)
print("\nMulti-label classification results:")
for label, score in zip(result['labels'], result['scores']):
    if score > 0.5:  # Adjust this threshold as needed
        print(f"{label}: {score:.2f}")
```

```
## Salida
Text: The new smartphone features a high-resolution camera, 5G connectivity, and a powerful AI chip.

Multi-label classification results:
camera quality: 0.94
processing power: 0.78
```

La capacidad de manejar m칰ltiples etiquetas ampl칤a significativamente la aplicabilidad de ZSTC en escenarios del mundo real, donde la complejidad y la multidimensionalidad son la norma m치s que la excepci칩n.

## Buenas pr치cticas

La clasificaci칩n _Zero-Shot_, aunque es poderosa y vers치til, requiere un enfoque cuidadoso para maximizar su eficacia.
Quiero se침alar algunas buenas pr치cticas a tener en cuenta al trabajar con este enfoque:

### Manejo de la ambiguedad

Como hemos visto, los modelos de lenguaje pre-entrenados pueden ser muy buenos para inferir sobre el contexto y las
relaciones sem치nticas en un texto. Sin embargo, pueden tener dificultades con textos ambiguos o con m칰ltiples
interpretaciones. Es importante tener en cuenta la ambig칲edad y la incertidumbre en las predicciones del modelo y
considerar c칩mo manejarlas en su aplicaci칩n. Cuando m칰ltiple etiquetas parecen igualmente probables, es crucial analizar
los puntajes de confianza y considerar el contexto.

```python showLineNumbers
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)

ambiguous_text = "The bank by the river was crowded."
labels = ["financial institution", "river bank", "crowded place"]

result = classifier(ambiguous_text, labels)

print("Text:", ambiguous_text)

print("\nClassification results:")
for label, score in zip(result['labels'], result['scores']):
    print(f"{label}: {score:.2f}")

print("\nAnalysis:")
if max(result['scores']) - min(result['scores']) < 0.1:
    print("This case is ambiguous. Consider providing more context or refining the labels.")
else:
    print(f"The most likely interpretation is: {result['labels'][0]}")
```

```
## Salida
Text: The bank by the river was crowded.

Classification results:
crowded place: 0.50
river bank: 0.50
financial institution: 0.00

Analysis:
The most likely interpretation is: crowded place
```

En el anterior ejemplo, hemos establecido un umbral de diferencia de 0.1 para identificar casos ambiguos. Cuando se
detecta ambiguedad en las predicciones, hay que considerar proporcionar m치s contexto o refinar las etiquetas para
mejorar la precisi칩n de la clasificaci칩n. Y en aplicaciones cr칤ticas, implementar un sistema de revisi칩n human para
casos ambiguos.

### Selecci칩n cuidadosa de etiquetas

La elecci칩n de etiquetas puede tener un impacto significativo en el rendimiento del modelo:

- Usar etiquetas claras y mutuamente excluyentes cuando sea posible.
- Evitar etiquetas demasiado generales o demasiado espec칤ficas.
- Considerar m칰ltiples formulaciones de la misma etiqueta para capturar diferentes matices.

```python showLineNumbers
good_labels = ["technology news", "sports report", "financial analysis"]
poor_labels = ["news", "report", "article"]  # Demasiado amplias
```

### Preprocesamiento de texto

El preprocesamiento adecuado puede mejorar la precisio칩n de la clasificaci칩n:

- Eliminar informaci칩n irrelevante o ruido del texto de entrada.
- Normalizar el texto (min칰sculas, eliminaci칩n de signos de puntuaci칩n, etc.).
- Considerar la expansi칩n de acr칩nimos o

### Uso de prompt engineering

La forma en que formula la tarea puede afectar el rendimiento del modelo:

```python showLineNumbers
# Enfoque est치ndar
result = classifier(text, labels)

# Con prompt engineering
hypothesis_template = "This text is about {}."
result = classifier(text, labels, hypothesis_template=hypothesis_template)
```

### Validaci칩n y ajuste

Implementar un proceso de validaci칩n continua:

- Usar un conjunto de datos de prueba para evaluar regularmente el rendimiento.
- Ajustar las etiquetas y el modelo seg칰n sea necesario.
- Considerar el fine-tuning del modelo base si se dispone de suficientes datos espec칤ficoss del dominio.

### Manejo de casos de baja confianza

Implementar estrategias para manejar predicciones de baja confianza:

```python showLineNumbers
confidence_threshold = 0.5
result = classifier(text, labels)
if max(result['scores']) < confidence_threshold:
    print("Low confidence prediction. Consider manual review.")
```

## Casos de uso

La clasificaci칩n _Zero-Shot_ tiene una amplia gama de aplicaciones en diversas industrias y campos. Veamos algunos
ejemplos:

1. **Clasificaci칩n de correos electr칩nicos en un entorno corporativo**:

```python showLineNumbers
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)

def classify_email(email_body):
    labels = ["Urgent", "Sales Lead", "Technical Support", "HR Related", "General Inquiry"]
    confidence_threshold = 0.6

    result = classifier(email_body, labels)
    top_label = result['labels'][0]
    top_score = result['scores'][0]

    if top_score < confidence_threshold:
        return "Needs Human Review", top_score
    else:
        return top_label, top_score

# Ejemplos de uso
email_body = "We need to schedule an urgent meeting to discuss the Q3 financial reports."
category, confidence = classify_email(email_body)

print(f"Email Category: {category}")
print(f"Confidence: {confidence:.2f}")

if category == "Needs Human Review":
    print("This email requires manual classification.")
else:
    print(f"Automated action: Route to {category} department")
```

```
## Salida
Email Category: Urgent
Confidence: 0.94
Automated action: Route to Urgent department
```

2. **An치lisis de sentimientos en rese침as de productos**:

```python showLineNumbers
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)

def analyze_product_review(review):
    labels = ["Positive", "Negative", "Neutral"]
    aspect_labels = ["Quality", "Price", "Customer Service", "Usability"]
    confidence_threshold = 0.7

    sentiment_result = classifier(review, labels)
    aspect_result = classifier(review, aspect_labels, multi_label=True)

    sentiment = sentiment_result['labels'][0]
    sentiment_score = sentiment_result['scores'][0]

    if sentiment_score < confidence_threshold:
        sentiment = "Ambiguous"

    aspects = [label for label, score in zip(aspect_result['labels'], aspect_result['scores']) if score > 0.5]

    return sentiment, aspects

# Ejemplo de uso
review = "The product is well-made but a bit overpriced. The customer support was helpful when I had questions."
sentiment, aspects = analyze_product_review(review)

print(f"Overall Sentiment: {sentiment}")
print(f"Aspects Mentioned: {', '.join(aspects)}")

if sentiment == "Ambiguous":
    print("This review needs further analysis for accurate sentiment classification.")
```

```
## Salida
Overall Sentiment: Ambiguous
Aspects Mentioned: Quality, Price, Customer Service
This review needs further analysis for accurate sentiment classification.
```

3. **Clasificador de noticias para una agregador de contenido**:

```python showLineNumbers
from transformers import pipeline
import numpy as np

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)

def categorize_news_article(article_text):
    main_categories = ["Politics", "Technology", "Sports", "Entertainment", "Business", "Science"]
    sub_categories = {
        "Politics": ["Domestic", "International", "Election", "Policy"],
        "Technology": ["AI", "Cybersecurity", "Gadgets", "Internet"],
        "Sports": ["Football", "Basketball", "Tennis", "Olympics"],
        "Entertainment": ["Movies", "Music", "Celebrity", "TV Shows"],
        "Business": ["Stock Market", "Startups", "Economy", "Corporate"],
        "Science": ["Space", "Climate", "Medicine", "Biology"]
    }

    confidence_threshold = 0.4

    # Clasificaci칩n de categor칤a principal
    main_result = classifier(article_text, main_categories)
    main_category = main_result['labels'][0]
    main_score = main_result['scores'][0]

    if main_score < confidence_threshold:
        return "Uncategorized", [], main_score

    # Clasificaci칩n de subcategor칤a
    sub_result = classifier(article_text, sub_categories[main_category])
    sub_category = sub_result['labels'][0]
    sub_score = sub_result['scores'][0]

    # Calcular confianza promedio
    avg_confidence = np.mean([main_score, sub_score])

    if avg_confidence < confidence_threshold:
        return main_category, [], avg_confidence
    else:
        return main_category, [sub_category], avg_confidence

# Ejemplo de uso
article = """
SpaceX successfully launched its latest batch of Starlink satellites into orbit on Monday.
The mission, which took off from Cape Canaveral, Florida, deployed 60 new satellites,
expanding the company's growing constellation of broadband internet satellites.
"""

main_category, sub_categories, confidence = categorize_news_article(article)

print(f"Main Category: {main_category}")
if sub_categories:
    print(f"Sub-Category: {sub_categories[0]}")
print(f"Confidence: {confidence:.2f}")

if confidence < 0.4:
    print("This article needs manual review for accurate categorization.")
elif not sub_categories:
    print("Could not determine a specific sub-category. Consider refining the classification.")
```

```
## Salida
Main Category: Uncategorized
Confidence: 0.33
This article needs manual review for accurate categorization.
```

Tambi칠n es posible combinar _Zero-Shot_ con otros m칠todos de NLP para mejorar los resultados, como la extracci칩n de
entidades, la clasificaci칩n de intenciones o la generaci칩n de texto.

4. **An치lisis de noticias financieras**

```python showLineNumbers
from transformers import pipeline

# Inicializar modelos
zero_shot_classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
ner_pipeline = pipeline("ner", model="dbmdz/bert-large-cased-finetuned-conll03-english")

def analyze_financial_news(text):
    # Categor칤as para Zero-Shot
    categories = ["Stock Market", "Mergers and Acquisitions", "Earnings Report", "Economic Policy"]

    # Realizar Zero-Shot Classification
    zs_result = zero_shot_classifier(text, categories)

    # Realizar NER
    ner_result = ner_pipeline(text)

    # Extraer entidades relevantes
    companies = set([entity['word'] for entity in ner_result if entity['entity'] == 'I-ORG'])

    # Combinar resultados
    confidence_threshold = 0.5
    top_category = zs_result['labels'][0]
    confidence = zs_result['scores'][0]

    if confidence < confidence_threshold:
        print("Low confidence prediction. Consider manual review.")
        return None, companies

    return top_category, companies

# Ejemplo de uso
news_text = "Apple Inc. reported record-breaking quarterly earnings, exceeding Wall Street expectations. The tech giant's stock surged in after-hours trading."

category, mentioned_companies = analyze_financial_news(news_text)

if category:
    print(f"News Category: {category}")
    print(f"Mentioned Companies: {', '.join(mentioned_companies)}")
```

```
## Salida
News Category: Earnings Report
Mentioned Companies: Apple, Inc
```

5. **Clasificaci칩n de Tweets con contexto de ssuario**

```python showLineNumbers
from transformers import pipeline

zero_shot_classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
ner_pipeline = pipeline("ner", model="dbmdz/bert-large-cased-finetuned-conll03-english")

def classify_tweet_with_context(tweet, user_bio):
    # Categor칤as para Zero-Shot
    categories = ["Technology", "Politics", "Entertainment", "Sports", "Science"]

    # Realizar Zero-Shot Classification en el tweet
    zs_result = zero_shot_classifier(tweet, categories)

    # Realizar NER en la bio del usuario
    ner_result = ner_pipeline(user_bio)

    # Extraer entidades relevantes de la bio
    user_interests = set([entity['word'] for entity in ner_result if entity['entity'] in ['I-ORG', 'I-MISC']])

    # Combinar resultados
    confidence_threshold = 0.5
    top_category = zs_result['labels'][0]
    confidence = zs_result['scores'][0]

    if confidence < confidence_threshold:
        # Si la confianza es baja, usar la bio del usuario para inferir categor칤a
        for interest in user_interests:
            interest_result = zero_shot_classifier(interest, categories)
            if interest_result['scores'][0] > confidence:
                top_category = interest_result['labels'][0]
                confidence = interest_result['scores'][0]

    if confidence < confidence_threshold:
        print("Low confidence prediction. Consider manual review.")
        return None

    return top_category

# Ejemplo de uso
tweet = "Just watched the latest episode. Mind blown!"
user_bio = "Tech enthusiast. AI researcher at Google. Avid sci-fi reader."

category = classify_tweet_with_context(tweet, user_bio)

if category:
    print(f"Tweet Category: {category}")
```

```
## Salida
Tweet Category: Entertainment
```

## Evaluaci칩n y m칠tricas

La evaluaci칩n del rendimiento de los modelos de clasificaci칩n _Zero-Shot_ es crucial para entender su efectividad y limitaciones. A diferencia de los m칠todos tradicionales, estos modelos se prueban en categor칤as no vistas durante el entrenamiento, lo que requiere un enfoque de evaluaci칩n espec칤fico.
Para ilustrar este proceso, utilizaremos el conjunto de datos AG News, que contiene noticias de cuatro categor칤as:
World, Sports, Business y Sci/Tech. Implementaremos un clasificador _Zero-Shot_ utilizando el modelo BART-large-mnli y
evaluaremos su rendimiento con diversas m칠tricas.

```python showLineNumbers
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import pipeline
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# Cargar el conjunto de datos AG News
def load_ag_news():
    train_data = pd.read_csv('https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv', header=None)
    test_data = pd.read_csv('https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv', header=None)
    data = pd.concat([train_data, test_data], axis=0)
    data.columns = ['Class', 'Title', 'Content']
    data['Text'] = data['Title'] + " " + data['Content']
    return data

# Cargar y preparar los datos
data = load_ag_news()
class_mapping = {1: "World", 2: "Sports", 3: "Business", 4: "Sci/Tech"}
data['Class'] = data['Class'].map(class_mapping)

# Tomar una muestra aleatoria para reducir el tiempo de procesamiento
sample_size = 1000  # Ajusta este n칰mero seg칰n tu capacidad de procesamiento
data_sample = data.sample(n=sample_size, random_state=42)

# Dividir en conjuntos de entrenamiento y prueba
train_data, test_data = train_test_split(data_sample, test_size=0.2, random_state=42)

# Preparar el clasificador Zero-Shot
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)

# Funci칩n para evaluar el clasificador
def evaluate_zero_shot_classifier(test_data, all_labels):
    true_labels = []
    predicted_labels = []
    confidences = []

    for _, row in tqdm(test_data.iterrows(), total=len(test_data)):
        result = classifier(row['Text'], all_labels)
        predicted_label = result['labels'][0]

        true_labels.append(row['Class'])
        predicted_labels.append(predicted_label)
        confidences.append(result['scores'][0])

    return true_labels, predicted_labels, confidences

# Evaluar el clasificador
all_labels = list(class_mapping.values())
true_labels, predicted_labels, confidences = evaluate_zero_shot_classifier(test_data, all_labels)

# Calcular m칠tricas
accuracy = accuracy_score(true_labels, predicted_labels)
print(f"Overall accuracy: {accuracy:.2f}")

print("\nClassification Report:")
print(classification_report(true_labels, predicted_labels, target_names=all_labels))

# Visualizar la matriz de confusi칩n
cm = confusion_matrix(true_labels, predicted_labels, labels=all_labels)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=all_labels, yticklabels=all_labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Visualizar la distribuci칩n de confianza
plt.figure(figsize=(10, 6))
sns.histplot(confidences, kde=True)
plt.title('Distribution of Confidence Scores')
plt.xlabel('Confidence')
plt.ylabel('Count')
plt.show()

# Calcular estad칤sticas adicionales
mean_confidence = np.mean(confidences)
median_confidence = np.median(confidences)
std_confidence = np.std(confidences)

print(f"\nMean Confidence: {mean_confidence:.2f}")
print(f"Median Confidence: {median_confidence:.2f}")
print(f"Standard Deviation of Confidence: {std_confidence:.2f}")

# Calcular precisi칩n por clase
per_class_accuracy = {}
for label in all_labels:
    mask = np.array(true_labels) == label
    per_class_accuracy[label] = accuracy_score(np.array(true_labels)[mask], np.array(predicted_labels)[mask])

print("\nPer-Class Accuracy:")
for label, acc in per_class_accuracy.items():
    print(f"{label}: {acc:.2f}")

# Visualizar precisi칩n por clase
plt.figure(figsize=(12, 6))
sns.barplot(x=list(per_class_accuracy.keys()), y=list(per_class_accuracy.values()))
plt.title('Per-Class Accuracy')
plt.xlabel('Class')
plt.ylabel('Accuracy')
plt.xticks(rotation=45)
plt.show()
```

Este c칩digo eval칰a el clasificador _Zero-Shot_ utilizando m칠tricas est치ndar como precisi칩n, recall y F1-score. Adem치s,
genera visualizaciones como la matriz de confusi칩n y la distribuci칩n de puntajes de confianza, proporcionando insights
sobre el rendimiento del modelo en diferentes categor칤as y su nivel de certeza en las predicciones.

La evaluaci칩n en un conjunto de datos real como AG News permite una comprensi칩n m치s profunda de c칩mo el modelo se
comporta en escenarios pr치cticos, revelando sus fortalezas y 치reas de mejora en la clasificaci칩n de texto sin
entrenamiento espec칤fico.

Los resultados se muestran a continuaci칩n:

```
## Salida
Overall accuracy: 0.74

Classification Report:
              precision    recall  f1-score   support

       World       0.62      0.70      0.65        46
      Sports       0.76      0.51      0.61        51
    Business       0.93      0.94      0.94        54
    Sci/Tech       0.68      0.82      0.74        49

    accuracy                           0.74       200
   macro avg       0.75      0.74      0.74       200
weighted avg       0.75      0.74      0.74       200
```

<ImageBox src="/images/ai/zero-shot-v01.png" alt="Matrix de confusi칩n" width="780px" height="701px">
  **Figura 5**. Matriz de confusi칩n que muestra la distribuci칩n de predicciones correctas e
  incorrectas en diferentes categor칤as.
</ImageBox>

<ImageBox
  src="/images/ai/zero-shot-v02.png"
  alt="Distribuci칩n de puntajes de confianza"
  width="841px"
  height="547px"
>
  **Figura 6**. Distribuci칩n de puntajes de confianza para las predicciones del clasificador
  _Zero-Shot_.
</ImageBox>

```
Mean Confidence: 0.54
Median Confidence: 0.50
Standard Deviation of Confidence: 0.16

Per-Class Accuracy:
World: 0.82
Sports: 0.94
Business: 0.70
Sci/Tech: 0.51
```

<ImageBox
  src="/images/ai/zero-shot-v03.png"
  alt="Precisi칩n por clase"
  width="1001px"
  height="586px"
>
  **Figura 7**. Precisi칩n por clase en la clasificaci칩n _Zero-Shot_ de noticias AG.
</ImageBox>

El informe de clasificaci칩n muestra un rendimiento variado del modelo _Zero-Shot_ en las diferentes categor칤as del
conjunto de datos AG News. La precisi칩n general del modelo es del 74%, lo cual es bastante bueno para un enfoque
_Zero-Shot_. La categor칤a 춺Business췉 se destaca con un excelente rendimiento (F1-score de 0.94), sugiriendo que el modelo
identifica muy bien este tipo de contenido. 춺Sci/Tech췉 tambi칠n muestra un buen desempe침o (F1-score de 0.74). Sin
embargo, el modelo parece tener m치s dificultades con 춺World췉 y 춺Sports췉, con F1-scores de 0.65 y 0.61 respectivamente.
Esto podr칤a indicar que estas categor칤as son m치s desafiantes de distinguir o que sus caracter칤sticas sem치nticas son
menos distintivas para el modelo. En general, el clasificador muestra un rendimiento prometedor, especialmente
considerando que no fue entrenado espec칤ficamente en este conjunto de datos.

## Limitaciones y consideraciones

Aunque la clasificaci칩n _Zero-Shot_ es poderosa, tiene sus limitaciones. El rendimiento del modelo depende de la calidad
del pre-entrenamiento y de la relaci칩n sem치ntica entre la entrada y las etiquetas. Puede tener dificultades con dominios
altamente especializados o conceptos alejados de sus datos de entrenamiento. Siempre es importante validar los
resultados y considerar el fine-tuning para casos de uso espec칤ficos.

```python showLineNumbers
from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)

# Example of a limitation: highly specialized domain
specialized_text = "The patient exhibits signs of keratoconus in the left eye."
general_labels = ["health", "sports", "technology"]
specialized_labels = ["ophthalmology", "cardiology", "neurology"]

print("General labels:")
print(classifier(specialized_text, general_labels))

print("\nSpecialized labels:")
print(classifier(specialized_text, specialized_labels))

# Example of a concept far from training data
unusual_text = "The zorblax fluttered its tentacles in the crimson sky of Xargon-7."
labels = ["science fiction", "historical fiction", "romance", "mystery"]

print("\nUnusual concept:")
print(classifier(unusual_text, labels))
```

```
## Salida
General labels:
{'sequence': 'The patient exhibits signs of keratoconus in the left eye.', 'labels': ['health', 'technology', 'sports'], 'scores': [0.7707374095916748, 0.135053813457489, 0.0942087471485138]}

Specialized labels:
{'sequence': 'The patient exhibits signs of keratoconus in the left eye.', 'labels': ['ophthalmology', 'neurology', 'cardiology'], 'scores': [0.9111181497573853, 0.06408613175153732, 0.02479572966694832]}

Unusual concept:
{'sequence': 'The zorblax fluttered its tentacles in the crimson sky of Xargon-7.', 'labels': ['science fiction', 'mystery', 'historical fiction', 'romance'], 'scores': [0.48209530115127563, 0.2437402755022049, 0.16008099913597107, 0.11408346891403198]}
```

Algunos puntos adicionales a considerar:

1. Sensibilidad a la formulaci칩n: El rendimiento puede variar significativamente seg칰n c칩mo se formulen las etiquetas de
   clase.

2. Sesgo del modelo: Los modelos pre-entrenados pueden reflejar sesgos presentes en sus datos de entrenamiento.

3. Limitaciones de contexto: Pueden tener dificultades con tareas que requieren un conocimiento contextual extenso o
   razonamiento complejo.

4. Escalabilidad: El tiempo de inferencia puede aumentar con el n칰mero de clases potenciales.

5. Interpretabilidad: Puede ser dif칤cil entender exactamente c칩mo el modelo llega a sus decisiones.

Es crucial realizar una evaluaci칩n exhaustiva en el dominio espec칤fico de aplicaci칩n y considerar estas limitaciones al
implementar soluciones basadas en clasificaci칩n _Zero-Shot_.

## Conclusiones

ZSTC ofrece un enfoque transformador para la categorizaci칩n de datos textuales, especialmente en escenarios donde los
datos etiquetados son escasos o costosos de obtener. Al aprovechar el conocimiento incrustado en los modelos de lenguaje
preentrenados, ZSTC puede generalizar a nuevas categor칤as y dominios sin necesidad de ejemplos de entrenamiento
expl칤citos. Esta capacidad abre un mundo de posibilidades para automatizar tareas como el enrutamiento de correos
electr칩nicos, el an치lisis de sentimientos, la categorizaci칩n de noticias y el an치lisis de noticias financieras.

Sin embargo, un aspecto que no se ha considerado en este an치lisis es el consumo de recursos computacionales,
como el uso de GPU, que puede ser significativo en la clasificaci칩n _Zero-Shot_. A pesar de que ZSTC ofrece ventajas en
t칠rminos de ahorro de tiempo y etiquetado, el costo computacional sigue siendo un factor a tener en cuenta,
especialmente para modelos de gran tama침o que requieren hardware especializado para ejecutar las inferencias de manera
eficiente. El consumo de recursos puede ser decisivo a la hora de elegir ZSTC frente a otros m칠todos,
sigue siendo un aspecto que podr칤a influir en determinadas aplicaciones y entornos donde los recursos son limitados o costosos.

La flexibilidad de ZSTC permite una r치pida adaptaci칩n a categor칤as en evoluci칩n y la incorporaci칩n de descripciones de
clases matizadas, lo que lo hace altamente vers치til para aplicaciones del mundo real. Adem치s, reduce la dependencia de
grandes conjuntos de datos etiquetados, ahorrando tiempo y recursos, al mismo tiempo que permite escalar a un gran
n칰mero de categor칤as.

Sin embargo, es crucial reconocer las limitaciones de ZSTC. El rendimiento del modelo depende en gran medida de la
calidad de sus datos de preentrenamiento y de la relaci칩n sem치ntica entre el texto de entrada y las etiquetas
proporcionadas. La ambig칲edad en el texto, los dominios altamente especializados y los conceptos alejados de los datos
de entrenamiento del modelo pueden presentar desaf칤os.

Para maximizar la efectividad de ZSTC, se debe prestar especial atenci칩n a la selecci칩n de etiquetas,
el preprocesamiento de texto y el dise침o de prompts. Implementar un proceso de validaci칩n robusto, manejar las
predicciones de baja confianza y abordar posibles sesgos en el modelo son esenciales para implementaciones confiables.
A medida que ZSTC sigue avanzando, una comprensi칩n profunda de sus capacidades, limitaciones e implicaciones 칠ticas ser치
fundamental para aprovechar todo su potencial en diversas aplicaciones basadas en texto.

Finalmente,si hay errores, omisiones o inexactitudes en este art칤culo, por favor no dude en contactarnos a trav칠s de
siguiente canal de Discord: [Math & Code](https://discord.gg/gJ3vCgSWeh).

## Referencias

<Reference
  type="image"
  url="https://unsplash.com/photos/chart-treemap-chart-GjBPLkTDzt4"
  text="Ben Wicks - Chart Treemap"
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/1707.00600"
  text="Yongqin Xian et al. 2020. Zero-Shot Learning -- A
Comprehensive Evaluation of the Good, the Bad and the Ugly"
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/1912.10165"
  text="Raul Puri et al. 2019. Zero-shot Text Classification With Generative Language Models"
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/1709.01643"
  text="Alexander J. et al. 2017. Learning to Compose
Domain-Specific Transformations for Data Augmentation"
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/2011.08641"
  text="Farhad Pourpanah et al. 2022. A Review of Generalized Zero-Shot Learning Methods"
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/1909.00161"
  text="Wenpeng Yin et al. 2019. Benchmarking Zero-shot
Text Classification: Datasets, Evaluation and Entailment Approach"
/>
<Reference
  type="huggingface"
  url="https://huggingface.co/docs/setfit/en/how_to/zero_shot"
  text="Zero-shot Text
Classification"
/>
<Reference
  type="web"
  url="https://joeddav.github.io/blog/2020/05/29/ZSL.html"
  text="Joe Davison. 2020. Zero-Shot
Learning in Modern NLP"
/>
<Reference
  type="web"
  url="https://www.diva-portal.org/smash/get/diva2:1613200/FULLTEXT01.pdf"
  text="Jacob Aslund. 2021.
Zero/Few-Shot Text Classification"
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/2001.07676"
  text="Timo Schick et al.
2021. Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference"
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/1712.05972"
  text="Pushpankar et al.
2017. Train Once, Test Anywhere: Zero-Shot Learning for Text Classification"
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/2405.03565v1"
  text="Han Liu et al.
2024. Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing"
/>
<Reference
  type="youtube"
  url="https://www.youtube.com/watch?app=desktop&v=q6iX1LdzgI0"
  text="Text Entailment approach
for Zero-shot Text Classification."
/>
<Reference
  type="web"
  url="https://www.vennify.ai/zero-shot-text-classification/"
  text="Vennify. 2021. Zero-Shot Text Classification Made Easy"
/>
<Reference
  type="github"
  url="https://github.com/claudio1975/Medium-blog/blob/master/Zero_Shot_Text_Classification/zero_shot_text_classification_hugging_face.ipynb"
  text="Claudio. 2023. What is zero-shot text classification?"
/>
<Reference
  type="web"
  url="https://aws.amazon.com/blogs/machine-learning/zero-shot-text-classification-with-amazon-sagemaker-jumpstart/"
  text="David Laredo. 2023. Zero-shot text classification with Amazon SageMaker JumpStart"
/>
<Reference
  type="devto"
  url="https://dev.to/abderrahimal/zero-shot-text-classification-under-the-hood-3h19"
  text="abderrahimal Alakouche. 2024. Zero Shot Text Classification Under the hood"
/>
<Reference
  type="web"
  url="https://aclanthology.org/2023.eacl-main.22.pdf"
  text="Marc Pamies et al. 2023. A weakly supervised textual entailment approach for zero-shot text classification."
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/2406.15241"
  text="Tassallah Abdullahi et al. 2024. Retrieval Augmented Zero-Shot Text Classification."
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/1603.08895"
  text="Yongqin Xian et al. 2016. Latent Embeddings for Zero-Shot classification."
/>
<Reference
  type="arxiv"
  url="https://arxiv.org/abs/2406.15241"
  text="Kishaloy et al. 2020. Task-Aware Representation of Sentences for Generic Text Classification"
/>
<Reference
  type="github"
  url="https://github.com/xbeat/Machine-Learning/blob/main/Zero-Shot%20Classification%20with%20Python.md"
  text="Giuseppe Canale. 2024. Zero-Shot Classification with Python"
/>
